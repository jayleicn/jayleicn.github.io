%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Medium Length Professional CV
% LaTeX Template
% Version 2.0 (8/5/13)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Trey Hunner (http://www.treyhunner.com/)
%
% Important note:
% This template requires the resume.cls file to be in the same directory as the
% .tex file. The resume.cls file provides the resume style used for structuring the
% document.
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass{resume} % Use the custom resume.cls style

\usepackage[left=0.75in,top=0.6in,right=0.75in,bottom=0.6in]{geometry} % Document margins
\usepackage{hyperref}
\usepackage{xcolor}
\usepackage{fontawesome}
\definecolor{codelinkcolor}{rgb}{0., 0., 0.}
\definecolor{bittersweet}{rgb}{1.0, 0.44, 0.37}
% \definecolor{bluedefrance}{rgb}{0.19, 0.55, 0.91}

\name{Jie Lei} % Your name


\address{Email: jayleicn@gmail.com \hfill Website: \href{https://jayleicn.github.io/}{https://jayleicn.github.io/}}
\address{Phone: 919-564-8651\hfill
         Github: \href{https://github.com/jayleicn}{https://github.com/jayleicn} }
\address{\hfill Updated June 2022}  
\begin{document}


%----------------------------------------------------------------------------------------
%	Current SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{Work Experience}


    \begin{rSubsection}{Meta AI}{June 2022 - present}{Research Scientist}{Seattle, WA}
        \item Work on vision and language research and products.
    \end{rSubsection}    

    \end{rSection}

%----------------------------------------------------------------------------------------
%	EDUCATION SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{Education}

{\bf University of North Carolina at Chapel Hill} \hfill {Aug 2017  -  May 2022} \\ 
{\sl Ph.D.} in Computer Science \\
Advisors: \href{http://www.tamaraberg.com/}{Tamara L. Berg} and \href{http://www.cs.unc.edu/~mbansal/}{Mohit Bansal}

{\bf University of Electronic Science and Technology of China (UESTC)} \hfill {Sep 2013 - Jun 2017} \\ 
{\sl B.Eng} in Computer Science \& Technology, Yingcai Honors College\\
Advisor: \href{https://personal.ntu.edu.sg/sinnopan/}{Sinno Jialin Pan} (NTU, Singapore)
\end{rSection}

%----------------------------------------------------------------------------------------
%	WORK EXPERIENCE SECTION
%----------------------------------------------------------------------------------------

\begin{rSection}{Intern Experience}

\begin{rSubsection}{University of North Carolina at Chapel Hill}{Aug 2017 - May 2022}{Research Assistant with \href{http://www.tamaraberg.com/}{Tamara L. Berg} and \href{http://www.cs.unc.edu/~mbansal/}{Mohit Bansal}}{Chapel Hill, NC}
\item Vision and language understanding, esp. video and language.
\end{rSubsection}


%------------------------------------------------


\begin{rSubsection}{Facebook AI}{May 2021 - Dec 2021}{Research Scientist Intern with 
    \href{https://lichengunc.github.io/}{Licheng Yu},
    \href{http://xinleic.xyz/}{Xinlei Chen} and \href{https://scholar.google.com/citations?user=DplAah0AAAAJ&hl=en}{Ning Zhang}} {Menlo Park, CA}
    \item Vision and language, especially image retrieval.
    \end{rSubsection}


%------------------------------------------------

\begin{rSubsection}{Microsoft Cloud \& AI}{May 2020 - Aug 2020}{Researcher Intern with 
    \href{https://scholar.google.com/citations?user=WR875gYAAAAJ&hl=en}{Linjie Li},
    \href{https://luoweizhou.github.io/}{Luowei Zhou}, \href{http://zhegan27.github.io/}{Zhe Gan} and
    \href{https://www.linkedin.com/in/jingjing-liu-65703431/}{Jingjing Liu}} {Bellevue, WA}
    \item End-to-end vision and language pretraining.
    \end{rSubsection}


%------------------------------------------------

\begin{rSubsection}{Tencent AI Lab}{May 2019 - Aug 2019}{Research Intern with 
    \href{http://www.deepcv.net/}{Liwei Wang}, 
    \href{https://scholar.google.com/citations?hl=en&user=S6OFEFEAAAAJ}{Yelong Shen} 
    and \href{https://scholar.google.com/citations?user=tMY31_gAAAAJ&hl=en}{Dong Yu}} {Bellevue, WA}
    \item Recurrent transformer for coherent video paragraph captioning.
    \end{rSubsection}

%------------------------------------------------

\begin{rSubsection}{Nanyang Technological University}{Oct 2016 - Apr 2017}{Research Intern with \href{https://personal.ntu.edu.sg/sinnopan/}{Sinno Jialin Pan}}{Singapore}
    \item Transfer learning in deep hash models for fast image retrieval.
    \end{rSubsection}

%------------------------------------------------

\begin{rSubsection}{University of Manitoba}{Jul 2016 - Oct 2016}{Research Intern with \href{https://www.cs.umanitoba.ca/~ywang/}{Yang Wang}}{Winnipeg, Canada}
    \item Weakly supervised image classification using hierarchical image labels.
    \end{rSubsection}

\end{rSection}

%----------------------------------------------------------------------------------------

\begin{rSection}{Publications}          
    \item {[18] 
    \textbf{Jie Lei}, Tamara L. Berg, Mohit Bansal,
    ``Revealing Single Frame Bias for Video-and-Language Learning'',
     arXiv 2022
    }        
    \item {[17] 
    Zhenhailong Wang, Manling Li, Ruochen Xu, Luowei Zhou,  \textbf{Jie Lei}, Xudong Lin, Shuohang Wang, Ziyi Yang, Chenguang Zhu, Derek Hoiem, Shih-Fu Chang, Mohit Bansal, Heng Ji,
    ``Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners",
     arXiv 2022
    }      
    \item {[16] 
    Yan-Bo Lin, \textbf{Jie Lei}, Mohit Bansal, Gedas Bertasius,
    ``ECLIPSE: Efficient Long-range Video Retrieval using Sight and Sound",
     arXiv 2022
    }      
    \item {[15] 
    \textbf{Jie Lei}, Xinlei Chen, Ning Zhang, Mengjiao Wang, Mohit Bansal, Tamara L. Berg, Licheng Yu,
    ``LoopITR: Combining Dual and Cross Encoder Architectures for Image-Text Retrieval", 
    arXiv 2022
    }         
    \item {[14] Hao Tan*, \textbf{Jie Lei*}, Thomas Wolf, Mohit Bansal,
            ``VIMPAC: Video Pre-Training via Masked Token Prediction and Contrastive Learning",
            CVPRW 2022.
            }         
    \item {[13] \textbf{Jie Lei}, Tamara L. Berg, Mohit Bansal,
            ``QVHighlights: Detecting Moments and Highlights in Videos via Natural Language Queries",
            NeurIPS 2021.
            }              
    \item {[12] Linjie Li*, \textbf{Jie Lei*}, Zhe Gan, Licheng Yu, Yen-Chun Chen, Rohit Pillai, Yu Cheng, Luowei Zhou, Xin Eric Wang, William Yang Wang, Tamara L. Berg, Mohit Bansal, Jingjing Liu, Lijuan Wang, Zicheng Liu,
            ``VALUE: A Multi-Task Benchmark for Video-and-Language Understanding Evaluation",
            NeurIPS 2021 Datasets and Benchmarks Track. 
            }            
    \item {[11] Linjie Li, \textbf{Jie Lei}, Zhe Gan, Jingjing Liu,
            ``Adversarial VQA: A New Benchmark for Evaluating the Robustness of VQA Models",
            ICCV 2021 {\color{bittersweet}\textbf{Oral}}. 
            }              
    \item {[10] \textbf{Jie Lei}, Tamara L. Berg, Mohit Bansal,
            ``mTVR: Multilingual Moment Retrieval in Videos",
            ACL 2021.
            }        
    \item {[9] Jaemin Cho, \textbf{Jie Lei}, Hao Tan, Mohit Bansal,
            ``Unifying Vision-and-Language Tasks via Text Generation",
            ICML 2021.    
            }       
    \item {[8] Zineng Tang*, \textbf{Jie Lei*}, Mohit Bansal,
            ``Improved Pre-Training from Noisy Instructional Videos via Dense Captions and Entropy Minimization",
            NAACL 2021.  
            }               
    \item {[7] \textbf{Jie Lei}*, Linjie Li*, Luowei Zhou, Zhe Gan, Tamara L. Berg, Mohit Bansal, Jingjing Liu,
            ``Less is More: ClipBERT for Video-and-Language Learning via Sparse Sampling",
            CVPR 2021 {\color{bittersweet}\textbf{Best Student Paper Honorable Mention, Oral}}.    
            }                  
    \item {[6] \textbf{Jie Lei}, Licheng Yu, Tamara L. Berg, Mohit Bansal,
            ``What is More Likely to Happen Next? Video and Language Future Event Prediction",
            EMNLP 2020.    
            }    
   \item {[5] \textbf{Jie Lei}, Licheng Yu, Tamara L. Berg, Mohit Bansal,
        ``TVR: A Large-Scale Dataset for Video-Subtitle Moment Retrieval'',
            ECCV 2020. 
            } 
   \item {[4] \textbf{Jie Lei}, Liwei Wang, Yelong Shen, Dong Yu, Tamara L. Berg, Mohit Bansal,
         ``MART: Memory-Augmented Recurrent Transformer for Coherent Video Paragraph Captioning'',
         ACL 2020.
         }               
   \item {[3] \textbf{Jie Lei}, Licheng Yu, Tamara L. Berg, Mohit Bansal,
               ``TVQA+: Spatio-Temporal Grounding for Video Question Answering'',
               ACL 2020.
               }
    \item {[2] \textbf{Jie Lei}, Licheng Yu, Mohit Bansal, Tamara L. Berg, 
               ``TVQA: Localized, Compositional Video Question Answering'',
               EMNLP 2018 {\color{bittersweet}\textbf{Oral}}.
               }
    \item {[1] \textbf{Jie Lei}, Zhenyu Guo, Yang Wang.
                ``Weakly Supervised Image Classification with Coarse and Fine Labels.''
                CRV 2017.
                }
\end{rSection}

%----------------------------------------------------------------------------------------
% Projects
%----------------------------------------------------------------------------------------

\begin{rSection}{Projects}
    \item {[1] \textbf{Jie Lei},
                ``AnimeGAN: Create Anime Face using Generative Adversarial Networks'',
                GitHub 2017.
                \\ $\cdot$\quad Implementation of GANs for anime face generation. 
                \href{https://github.com/jayleicn/animeGAN}{\color{codelinkcolor}\faGithub~Data \& Code} (\textbf{1K+ stars})
                \\ $\cdot$\quad Automatic pipeline for large-scale anime face dataset construction from the web.}
\end{rSection}


%----------------------------------------------------------------------------------------
% Awards
%----------------------------------------------------------------------------------------

\begin{rSection}{Awards}
\item {\textbf{\href{http://cvpr2021.thecvf.com/node/329}{Best Student Paper Honorable Mention}}, CVPR 2021, Virtual } \hfill {2021}    
\item {\textbf{\href{https://research.adobe.com/fellowship/}{Adobe Research Fellowship}}, Adobe, USA} \hfill {2021}    
\item {\textbf{Outstanding Undergraduate Thesis}, UESTC, China} \hfill {2017} 
\item {\textbf{\href{https://www.mitacs.ca/en/programs/globalink/globalink-research-internship}{Globalink Research Intern Award}} (200 undergraduates across China), \href{https://www.mitacs.ca/en}{Mitacs, Canada}. } \hfill {2016}
% \item {\textbf{Meritorious Winner}, Interdisciplinary Contest In Modeling, COMAP, USA} \hfill {2016} 
% \item {\textbf{Scholarship for Academic Excellence} (5\%), UESTC, China} \hfill {2015-2016}
% \item {\textbf{Futong Scholarship} (2\%), Futong Group, China} \hfill {2014}
\end{rSection}


\newpage

%----------------------------------------------------------------------------------------
% Activities
%----------------------------------------------------------------------------------------


\begin{rSection}{Academic Service}
    \textbf{Journal and Conference Reviewer}: TPAMI, IJCV, CVPR 2019-2022, ICCV 2019, ECCV 2020, ACM MM 2020 Interactive Arts, AAAI 2021, ICCV 2021, ACL 2021-2022, NeurIPS 2021, ICLR 2021, NeurIPS HAMLETS 2020 \\
    \textbf{Organizer}:  VALUE Challenge @ ICCV 2021, Transformer for Vision Workshop @ CVPR 2022 \\
    \textbf{Area Chair}: COLING 2022
    
    % Presenter at UNC middle/high school open house \hfill 2018
\end{rSection}

%----------------------------------------------------------------------------------------
%	TECHNICAL
%----------------------------------------------------------------------------------------

% \begin{rSection}{Technical \& Language}

%     \begin{tabular}{ @{} >{\bfseries}l @{\hspace{6ex}} l }
%     Programming & Python, JavaScript, HTML/CSS, Matlab, C$\backslash$C++, Lua\\
%     Tools & PyTorch, Linux, Vim, Git, Latex.  \\
%     \end{tabular}
    
%     \end{rSection}


\end{document}
